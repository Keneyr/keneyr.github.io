<!DOCTYPE html>
<html  lang="en">
<head>
    <meta charset="utf-8" />

<meta name="generator" content="Hexo 4.2.1" />

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

<title>PatterRecognition-C2-Probability-Distributions - QinranY&#39;s Homepage</title>


    <meta name="description" content="Keywords: Gaussian Distribution, The Exponential Family, Python">
<meta property="og:type" content="article">
<meta property="og:title" content="PatterRecognition-C2-Probability-Distributions">
<meta property="og:url" content="https://keneyr.com/MachineLearning/PatternRecognition/PatterRecognition-C2-Probability-Distributions/index.html">
<meta property="og:site_name" content="QinranY&#39;s Homepage">
<meta property="og:description" content="Keywords: Gaussian Distribution, The Exponential Family, Python">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://keneyr.com/images/og_image.png">
<meta property="article:published_time" content="2023-10-16T08:48:48.000Z">
<meta property="article:modified_time" content="2024-01-03T10:14:36.024Z">
<meta property="article:author" content="Keneyr">
<meta property="article:tag" content="MachineLearning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://keneyr.com/images/og_image.png">








<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/vs2015.css">


    
    
<style>body>.footer,body>.navbar,body>.section{opacity:0}</style>

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">

    
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">

    
    
    
    
<link rel="stylesheet" href="/css/back-to-top.css">

    
    
    
    
    
    
    
    <link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>
    
    <script async="" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    


<link rel="stylesheet" href="/css/style.css">
</head>
<body class="is-2-column">
    <nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                <img src="/images/beauty.jpg" alt="PatterRecognition-C2-Probability-Distributions" height="28">
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item"
                href="/">Home</a>
                
                <a class="navbar-item"
                href="/categories">Categories</a>
                
                <a class="navbar-item"
                href="/tags">Tags</a>
                
                <a class="navbar-item"
                href="/about">About</a>
                
                <a class="navbar-item"
                href="/publication">Publication</a>
                
                <a class="navbar-item"
                href="/projects">Projects</a>
                
                <a class="navbar-item"
                href="/life">Life</a>
                
                <a class="navbar-item"
                href="/work">Work</a>
                
                <a class="navbar-item"
                href="/Animation">Animation</a>
                
                <a class="navbar-item"
                href="/archives">Archives</a>
                
                <a class="navbar-item"
                href="/CV">CV</a>
                
                <a class="navbar-item"
                href="/extra">Extra</a>
                
            </div>
            
            <div class="navbar-end">
                
                    
                    <a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/Keneyr">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                    
                
                
                <a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;">
                    <i class="fas fa-list-ul"></i>
                </a>
                
                
                <a class="navbar-item search" title="Search" href="javascript:;">
                    <i class="fas fa-search"></i>
                </a>
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-8-tablet is-8-desktop is-9-widescreen has-order-2 column-main">
<div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2023-10-16T08:48:48.000Z">2023-10-16</time>
                
                <div class="level-item">
                <a class="has-link-grey -link" href="/categories/MachineLearning/">MachineLearning</a>&nbsp;/&nbsp;<a class="has-link-grey -link" href="/categories/MachineLearning/PatternRecognition/">PatternRecognition</a>
                </div>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    29 minutes read (About 4339 words)
                </span>
                
                
                <span class="level-item has-text-grey" id="busuanzi_container_page_pv">
                    <i class="far fa-eye"></i>
                    <span id="busuanzi_value_page_pv">0</span> visits
                </span>
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                PatterRecognition-C2-Probability-Distributions
            
        </h1>
        <div class="content">
            <p><strong><em>Keywords</em></strong>: Gaussian Distribution, The Exponential Family, Python</p>
<a id="more"></a>

<p>This is the Chapter2 ReadingNotes from book <em>Bishop-Pattern-Recognition-and-Machine-Learning-2006</em>. <a href="https://github.com/Keneyr/PRML">[Code_Python]</a></p>
<p>One role for the distributions discussed in this chapter is to model the probability distribution $p(\pmb{x})$ of a random variable $\pmb{x}$, given a finite set $\lbrace \pmb{x_1}, \cdots , \pmb{x_N} \rbrace$ of observations. This problem is known as <strong><em>density estimation</em></strong>.</p>
<h2 id="Binary-Variables"><a href="#Binary-Variables" class="headerlink" title="Binary Variables"></a>Binary Variables</h2><p>We begin by considering a <u>single binary random variable</u> $x \in \lbrace 0,1 \rbrace$. For example, $x$ might describe the outcome of flipping a coin, with $x = 1$ representing ‘heads’, and x = 0 representing ‘tails’.</p>
<p>The probability of $x = 1$ will be denoted by the parameter $\mu$ so that<br>$$<br>p(x=1|\mu) = \mu<br>\tag{2.1}<br>$$<br>where $0 \leq \mu \leq 1$, from which it follows that $p(x = 0|\mu) = 1 − \mu$. The probability distribution over $x$ can therefore be written in the form<br>$$<br>Bern(x | \mu) = \mu^x (1-\mu)^{1-x}<br>\tag{2.2}<br>$$<br>which is known as the <strong><em>Bernoulli distribution 伯努利分布</em></strong>.</p>
<p>It is easily verified that this distribution is normalized and that it has mean and variance given by<br>$$<br>E[x] = \mu<br>\tag{2.3}<br>$$<br>$$<br>var[x] = \mu(1-\mu)<br>\tag{2.4}<br>$$</p>
<p>Suppose we have a data set $D = \lbrace x_1, \cdots , x_N \rbrace$ of observed values of $x$, iid, so the likelyhood function is<br>$$<br>p(D|\mu) = \prod_{n=1}^{N} p(x_n|\mu) = \prod_{n=1}^{N} \mu^{x_n} (1 - \mu)^{1-x_n}<br>\tag{2.5}<br>$$</p>
<p>$$<br>\ln p(D|\mu) = \sum_{n=1}^{N} \ln p(x_n|\mu) = \sum_{n=1}^{N} \lbrace x_n\ln \mu + (1-x_n)\ln(1 - \mu) \rbrace<br>\tag{2.6}<br>$$</p>
<p>If we set the <u>derivative</u> of $\ln p(D|\mu)$  with respect to $\mu$ equal to zero, we obtain the maximum likelihood estimator<br>$$<br>\mu_{ML} = \frac{1}{N}\sum_{n=1}^{N} x_n<br>\tag{2.7}<br>$$<br>which is also known as the <strong><em>sample mean</em></strong>.<br>If we denote the number of observations of $x = 1$ (heads) within this data set by $m$, then we can write (2.7) in the form<br>$$<br>\mu_{ML} = \frac{m}{N}<br>\tag{2.8}<br>$$</p>
<p>We can also work out <u>the distribution of the number $m$</u> of observations of $x = 1$, given that the data set has size $N$. This is called the <strong><em>binomial distribution 二项分布</em></strong>,<br>$$<br>Bin(m|N,\mu) = \begin{pmatrix}<br>    N\\m<br>\end{pmatrix} \mu^m (1-\mu)^{N-m}<br>\tag{2.9}<br>$$<br>$$<br>E[m] = \sum_{m=1}^N m Bin(m|N,\mu) = N\mu\tag{2.11}<br>$$<br>$$<br>var[m] = N\mu(1-\mu)<br>\tag{2.12}<br>$$<br><img src="/images/PatternRecognition/c2/bionomial-distribution.png" alt="bionomial-distribution"></p>
<h3 id="The-beta-distribution"><a href="#The-beta-distribution" class="headerlink" title="The beta distribution"></a>The beta distribution</h3><p>we note that the likelihood function takes the form of the product of factors of the form $\mu^{x} (1 - \mu)^{1-x}$.</p>
<blockquote>
<p>If we choose a prior to be proportional to powers of $\mu$ and $(1 − \mu)$, then the posterior distribution, which is proportional to the product of the prior and the likelihood function, will have the same functional form as the prior. This property is called <strong><em>conjugacy 共轭</em></strong>.</p>
</blockquote>
<p>We therefore choose a prior, called the <strong><em>beta distribution</em></strong>, given by<br>$$<br>Beta(\mu | a, b)  = \frac{\Gamma (a+b)}{\Gamma(a) \Gamma(b)} \mu^{a-1}(1-\mu)^{b-1}<br>\tag{2.13}<br>$$<br>where $\Gamma(x)$ is the gamma function defined as<br>$$<br>\Gamma(t) = \int_0^{+\infty} x^{t-1}e^{-x}dx, t&gt;0<br>$$</p>
<p>$$<br>\int_0^1 Beta(\mu | a, b) d\mu = 1<br>\tag{2.14}<br>$$<br>The mean and variance of the beta distribution are given by<br>$$<br>E[\mu] = \frac{a}{a+b}<br>\tag{2.15}<br>$$<br>$$<br>var[\mu] = \frac{ab}{(a+b)^2 (a+b+1)}<br>\tag{2.16}<br>$$<br>By Bayes’s Therom and (2.13) and (2.9), this <u>posterior distribution</u></p>
<p>$$<br>p(\mu|m,l,a,b) \propto \mu^{m+a-1}(1-\mu)^{l+b-1}, l = N-m<br>\tag{2.17}<br>$$<br>it is simply another beta distribution, and its normalization coefficient can therefore be obtained by comparison with (2.13) to give</p>
<p>$$<br>p(\mu|m,l,a,b) = \frac{\Gamma (m+a+l+b)}{\Gamma(m+a) \Gamma(l+b)} \mu^{m+a-1}(1-\mu)^{l+b-1}, l = N-m<br>\tag{2.18}<br>$$</p>
<p><img src="/images/PatternRecognition/c2/Bayesian-view.png" alt="Bayesian view Sequential approach"></p>
<p>we must evaluate the predictive distribution of $x$, given the observed data set $D$.<br>$$<br>\begin{aligned}<br>p(x=1|D) &amp;= \int_0^1 p(x=1|\mu)p(\mu|D) d\mu \\ &amp;= \int_0^1 \mu p(\mu|D)d\mu \\ &amp;= E[\mu|D]\\<br>\underset{Together with (2.18),(2.15)}{\longrightarrow}<br>&amp;= \frac{m+a}{m+a+l+b}<br>\end{aligned}<br>\tag{2.19}<br>$$</p>
<blockquote>
<p>贝叶斯视角下的后验概率的均值，随着观察数据的增多，越来越趋向于最大似然数得到的结果。</p>
</blockquote>
<h2 id="Multinomial-Variables"><a href="#Multinomial-Variables" class="headerlink" title="Multinomial Variables"></a>Multinomial Variables</h2><p>If we have a variable that can take $K = 6$ states and a particular observation of the variable happens to correspond to the state where $x_3 = 1$, then $\pmb{x}$ will be represented by</p>
<p>$$<br>\pmb{x} = (0,0,1,0,0,0)^T<br>$$</p>
<p>where, $\sum_{k=1}^{K} x_k = 1$.</p>
<p>If we denote the probability of $x_k = 1$ by the parameter $\mu_k$, then the distribution of $\pmb{x}$ is given<br>$$<br>p(\pmb{x}|\pmb{\mu}) = \prod_{k=1}^{K} \mu_k^{x_k}<br>\tag{2.26}<br>$$<br>where, $\pmb{\mu} = (\mu_1, \cdots, \mu_K)^T$ and, $\sum_{k} \mu_k = 1$</p>
<p>The distribution (2.26) can be regarded as a generalization of the Bernoulli distribution to more than two outcomes. It is easily seen that the distribution is normalized<br>$$<br>\sum_{\pmb{x}} p(\pmb{x}|\pmb{\mu}) = \sum_{k=1}^{K} \mu_k = 1<br>$$</p>
<p>and</p>
<p>$$<br>E[\pmb{x}|\pmb{\mu}] = \sum_{\pmb{x}} p(\pmb{x}|\pmb{\mu}) \pmb{x} = \pmb{\mu}<br>\tag{2.28}<br>$$</p>
<p>By maximum likelihood, we get</p>
<p>$$<br>\mu_k^{ML} = \frac{m_k}{N}<br>\tag{2.33}<br>$$<br>which is the fraction of the $N$ observations for which $x_k = 1$.</p>
<p>The multinomial distribution is:<br>$$<br>Mult(m_1, m_2, \cdots, m_K | \pmb{\mu}, N) = \begin{pmatrix}N \\ m_1m_2\cdots m_K\end{pmatrix}\prod_{k=1}^{K} \mu_k^{m_k}<br>\tag{2.34}<br>$$</p>
<h3 id="The-Dirichlet-distribution"><a href="#The-Dirichlet-distribution" class="headerlink" title="The Dirichlet distribution"></a>The Dirichlet distribution</h3><p>By inspection of the form of the multinomial distribution, we see that the conjugate prior is given by</p>
<p>$$<br>p(\pmb{\mu}|\pmb{\alpha}) \propto \prod_{k=1}^{K} \mu_k ^{\alpha_{k}-1}<br>$$</p>
<p>the Dirichlet distribution is:<br>$$<br>Dir(\pmb{\mu}|\pmb{\alpha}) = \frac{\Gamma{(\alpha_0)}}{\Gamma{(\alpha_1)} \cdots \Gamma{(\alpha_K)}} \prod_{k=1}^K \mu_k^{\alpha_k - 1}<br>\tag{2.38}<br>$$</p>
<p>Multiplying the prior (2.38) by the likelihood function (2.34), we obtain the posterior distribution for the parameters ${\mu_k}$ in the form<br>$$<br>p(\pmb{\mu}|D,\pmb{alpha}) \propto p(D|\pmb{\mu}) p(\pmb{\mu}|\pmb{alpha}) \propto \prod_{k=1}^{K} \mu_k^{\alpha_k + m_k - 1}<br>\tag{2.40}<br>$$<br>We see that the posterior distribution again takes the form of a Dirichlet distribution, confirming that the Dirichlet is indeed a conjugate prior for the multinomial.</p>
<p><img src="/images/PatternRecognition/c2/Dirichlet-distribution.png" alt="Dirichlet distribution"></p>
<h2 id="The-Gaussian-Distribution"><a href="#The-Gaussian-Distribution" class="headerlink" title="The Gaussian Distribution"></a>The Gaussian Distribution</h2><p>For a $D$-dimensional vector $\pmb{x}$, the multivariate Gaussian distribution takes the form<br>$$<br> \mathcal{N}(\pmb{x} | \pmb{\mu}, \pmb{\Sigma}) = \frac{1}{(2\pi)^{D/2}}\frac{1}{|\pmb{\Sigma}|^{1/2}} exp \lbrace -\frac{1}{2}(\pmb{x - \mu})^T \pmb{\Sigma}^{-1}(\pmb{x-\mu}) \rbrace<br>\tag{2.43}<br>$$</p>
<p>Gaussian distribution arises is when we consider the sum of multiple random variables. The central limit theorem (due to Laplace) tells us that, subject to certain mild conditions, the sum of a set of random variables, which is of course itself a random variable, has a distribution that becomes increasingly Gaussian as the number of terms in the sum increases (Walker, 1969).</p>
<p>We begin by considering the <u>geometrical form of the Gaussian distribution</u>. The functional dependence of the Gaussian on $x$ is through the quadratic form (高斯函数对$x$的函数依赖性通过二次形式表现)</p>
<p>$$<br>\Delta^2 = (\pmb{x - \mu})^T \Sigma^{-1} (\pmb{x - \mu})<br>\tag{2.44}<br>$$<br>The quantity $\Delta$ is called the <strong>Mahalanobis distance</strong> from $\pmb{\mu}$ to $\pmb{x}$ and reduces to the <u>Euclidean distance</u> when $\Sigma$ is the <u>identity matrix</u>. <strong><em>The Gaussian distribution will be constant on surfaces in x-space for which this quadratic form is constant.</em></strong></p>
<p>The covariance matrix $\Sigma$ is a symmetric matrix, it can be expressed as an expansion in terms of its eigenvectors in the form<br>$$<br>\Sigma = \sum_{i=1}^{D} \lambda_i \pmb{u_i u_i^T}<br>\tag{2.48}<br>$$</p>
<p>&#x1F449;<a href="/Math/Linear-Algebra/Algebra-C7-Symmetric-Matrices-And-Quadratic-Forms/">More about Symmetric matrix and EigenVectors &gt;&gt;</a></p>
<p>$$<br>\Sigma^{-1} = \sum_{i=1}^{D} \frac{1}{\lambda_i} \pmb{u_i u_i^T}<br>\tag{2.49}<br>$$<br>Substituting (2.49) into (2.44), the quadratic form becomes<br>$$<br>\Delta^2 = \sum_{i=1}^{D} \frac{y_i^2}{\lambda_i}<br>\tag{2.50}<br>$$<br>where we have defined<br>$$<br>y_i = \pmb{u_i}^T(\pmb{x-\mu})<br>\tag{2.51}<br>$$</p>
<blockquote>
<p>$\pmb{x^TAx} = \pmb{y^TDy}$ where, $\pmb{x = Py}$ and $\pmb{P}$ is a matrix of eigen vectors of $\pmb{A}$.</p>
</blockquote>
<p>We can interpret ${y_i}$ as a new coordinate system defined by the orthonormal vectors $\pmb{u_i}$ that are shifted and rotated with respect to the original $x_i$ coordinates. Forming the vector $\pmb{y} = (y_1, \cdots, y_D)^T$, we have<br>$$<br>\pmb{y = U(x-\mu)}<br>\tag{2.52}<br>$$<br><strong><em>The quadratic form, and hence the Gaussian density, will be constant on surfaces for which (2.51) is constant.</em></strong></p>
<p>Now consider the form of the Gaussian distribution in the <u>new coordinate system defined by the $y_i$</u>.<br>In going from the $\pmb{x}$ to the $\pmb{y}$ coordinate system, we have a <strong>Jacobian matrix</strong> $J$ with elements given by<br>$$<br>J_{ij} = \frac{\partial x_i}{\partial y_j} = U_{ji}<br>\tag{2.53}<br>$$<br>thus<br>$$<br>|J|^2 = |U^T|^2 = 1<br>\tag{2.54}<br>$$<br>the determinant $|\Sigma|$ of the covariance matrix can be written as the product of its eigenvalues, and hence<br>$$<br>|\Sigma|^{1/2} = \prod_{j=1}^{D}\lambda_j^{1/2}<br>\tag{2.55}<br>$$</p>
<p>Thus in the $y_j$ coordinate system, the Gaussian distribution takes the form<br>$$<br>p(\pmb{y}) = p(\pmb{x})|J| = \prod_{j=1}^{D} \frac{1}{(2\pi\lambda_j)^{1/2}} exp\lbrace -\frac{y_j^2}{2\lambda_j} \rbrace<br>\tag{2.56}<br>$$<br>which is the product of $D$ independent univariate Gaussian distributions. ($D$ is the dimension of the vector, like $D = 2$, $\pmb{x} = (x_1, x_2)$)</p>
<blockquote>
<p>The eigenvectors therefore define a new set of shifted and rotated coordinates with respect to which the joint probability distribution <u>factorizes into</u> a product of independent distributions. The integral of the distribution in the $\pmb{y}$ coordinate system is then<br>$$<br>\int p(\pmb{y}) d\pmb{y} = \prod_{j=1}^{D} \int_{-\infty}^{\infty}  \frac{1}{(2\pi\lambda_j)^{1/2}} exp\lbrace -\frac{y_j^2}{2\lambda_j} \rbrace dy_j = 1<br>\tag{2.57}<br>$$<br>where we have used the result (1.48) for the normalization of the univariate Gaussian. This confirms that the multivariate Gaussian (2.43) is indeed normalized.<br>$$<br>\int_{-\infty}^{\infty}  \mathcal{N}(x|\mu, \sigma^2) dx = 1<br>\tag{1.48}<br>$$</p>
</blockquote>
<p>We now look at <strong><em>the moments of the Gaussian distribution</em></strong> and thereby provide an interpretation of the parameters $\pmb{\mu}$ and $\Sigma$.</p>
<p><a href="https://en.wikipedia.org/wiki/Moment_(mathematics)">https://en.wikipedia.org/wiki/Moment_(mathematics)</a></p>
<p>The expectation of $\pmb{x}$ under the Gaussian distribution is given by<br>$$<br>\begin{aligned}<br>E[\pmb{x}] &amp;= \frac{1}{(2\pi)^{D/2}}\frac{1}{|\pmb{\Sigma}|^{1/2}} \int exp \lbrace -\frac{1}{2}(\pmb{x - \mu})^T \pmb{\Sigma}^{-1}(\pmb{x-\mu}) \rbrace \pmb{x} d\pmb{x}\\<br>&amp;= \frac{1}{(2\pi)^{D/2}}\frac{1}{|\pmb{\Sigma}|^{1/2}} \int exp \lbrace -\frac{1}{2}\pmb{z}^T \pmb{\Sigma}^{-1}\pmb{z} \rbrace (\pmb{z+\mu}) d\pmb{z}\\<br>&amp;= \pmb{\mu}<br>\end{aligned}<br>\tag{2.58}<br>$$<br>and so we refer to $\pmb{\mu}$ as the mean of the Gaussian distribution.</p>
<p>We now consider <strong><em>second order moments of the Gaussian</em></strong>.(variance)</p>
<p>In the univariate case,<br>$$<br>E[x^2] = \int_{-\infty}^{\infty} N(x|\mu, \sigma^2) x^2 dx = \mu^2 + \sigma^2<br>\tag{1.50}<br>$$<br>$$<br>var[x] = E[x^2] - E[x]^2 = \sigma^2<br>\tag{1.51}<br>$$</p>
<p>thus, For the multivariate Gaussian<br>$$<br>\begin{aligned}<br>E[\pmb{xx^T}] &amp;= \frac{1}{(2\pi)^{D/2}}\frac{1}{|\pmb{\Sigma}|^{1/2}} \int exp \lbrace -\frac{1}{2}(\pmb{x - \mu})^T \pmb{\Sigma}^{-1}(\pmb{x-\mu}) \rbrace \pmb{xx^T} d\pmb{x}\\<br>&amp;= \frac{1}{(2\pi)^{D/2}}\frac{1}{|\pmb{\Sigma}|^{1/2}} \int exp \lbrace -\frac{1}{2}\pmb{z}^T \pmb{\Sigma}^{-1}\pmb{z} \rbrace (\pmb{z+\mu})(\pmb{z+\mu})^T d\pmb{z}\\<br>&amp;= \pmb{\mu\mu^T} + \frac{1}{(2\pi)^{D/2}}\frac{1}{|\pmb{\Sigma}|^{1/2}} \int exp \lbrace -\frac{1}{2}\pmb{z}^T \pmb{\Sigma}^{-1}\pmb{z} \rbrace \pmb{z}\pmb{z}^T d\pmb{z}\\<br>&amp;= \pmb{\mu\mu^T} + \sum_{i=1}^{D} \pmb{u_iu_i^T}\lambda_i\\<br>&amp;= \pmb{\mu\mu^T} + \Sigma<br>\end{aligned}<br>\tag{2.61}<br>$$<br>where,<br>$$<br>\begin{aligned}<br>\pmb{z} &amp;= \pmb{x-\mu}\\<br>&amp;= \sum_{j=1}^{D} y_j \pmb{u_j}<br>\end{aligned}<br>\tag{2.60}<br>$$<br>thus,<br>$$<br>cov[\pmb{x}] = \Sigma<br>\tag{2.64}<br>$$</p>
<p><img src="/images/PatternRecognition/c2/gaussian.png" alt="Gaussian distribution"></p>
<p>Gaussian distribution has some sever limitations:</p>
<ol>
<li>to many parameters, computation expensive.</li>
<li>intrinsically unimodal(单峰), unable to provide a good approximation to multimodal distributions.</li>
</ol>
<p>We will see later that the introduction of <strong><em>latent variables</em></strong>, also called hidden variables or unobserved variables, allows both of these problems to be addressed.</p>
<h3 id="Conditional-Gaussian-distributions"><a href="#Conditional-Gaussian-distributions" class="headerlink" title="Conditional Gaussian distributions"></a>Conditional Gaussian distributions</h3><p>Suppose $\pmb{x}$ is a $D$-dimensional vector with Gaussian distribution $N(\pmb{x}|\pmb{\mu}, \Sigma)$ and that we partition $\pmb{x}$ into two disjoint subsets $\pmb{x}_a$ and $\pmb{x}_b$. Without loss of generality, we can take $\pmb{x}_a$ to form the first $M$ components of $\pmb{x}$, with $\pmb{x}_b$ comprising the remaining $D−M$ components, so that</p>
<p>$$<br>\pmb{x} = \begin{pmatrix} \pmb{x_a} \\ \pmb{x_b}\end{pmatrix}<br>\tag{2.65}<br>$$</p>
<p>corresponding partitions of the mean vector $\pmb{\mu}$ and covariance matrix $\Sigma$ given by<br>$$<br>\pmb{\mu} = \begin{pmatrix} \pmb{\mu_a} \\ \pmb{\mu_b}\end{pmatrix}<br>\tag{2.66}<br>$$<br>$$<br>\Sigma = \begin{bmatrix} \Sigma_{aa} &amp; \Sigma_{ab} \\ \Sigma_{ba} &amp; \Sigma_{bb}\end{bmatrix}<br>\tag{2.67}<br>$$<br>where, $\Sigma^T = \Sigma$. The <strong>precision matrix</strong> $\Lambda = \Sigma^{-1}$.</p>
<p>Conditional distribution $p(\pmb{x_a|x_b})$ will be Gaussian:<br>$$<br>\pmb{\mu_{a|b}} = \pmb{\mu_a} + \Sigma_{ab}\Sigma_{bb}^{-1}(\pmb{x_b}-\pmb{\mu_b})<br>\tag{2.81}<br>$$<br>$$<br>\Sigma_{a|b} = \Sigma_{aa} - \Sigma_{ab}\Sigma_{bb}^{-1}\Sigma_{ba}<br>\tag{2.82}<br>$$</p>
<p>Note that the mean of the conditional distribution $p(\pmb{x_a|x_b})$, given by (2.81), is a linear function of $\pmb{x_b}$ and that the covariance, given by (2.82), is independent of $\pmb{x_a}$. This represents an example of a <strong><em>linear-Gaussian model</em></strong>.</p>
<h3 id="Marginal-Gaussian-distributions"><a href="#Marginal-Gaussian-distributions" class="headerlink" title="Marginal Gaussian distributions"></a>Marginal Gaussian distributions</h3><p>Now we turn to a discussion of the marginal distribution given by<br>$$<br>p(\pmb{x_a}) = \int p(\pmb{x_a, x_b}) d\pmb{x_b}<br>\tag{2.83}<br>$$<br>which, as we shall see, is also Gaussian.</p>
<p><img src="/images/PatternRecognition/c2/conditional-gaussian.png" alt="conditional Gaussian distribution"></p>
<h3 id="Bayes’-theorem-for-Gaussian-variables"><a href="#Bayes’-theorem-for-Gaussian-variables" class="headerlink" title="Bayes’ theorem for Gaussian variables"></a>Bayes’ theorem for Gaussian variables</h3><p>Here we shall suppose that we are given a Gaussian marginal distribution $p(\pmb{x})$ and a Gaussian conditional distribution $p(\pmb{y}|\pmb{x})$ in which $p(\pmb{y}|\pmb{x})$ has a mean that is a linear function of $\pmb{x}$, and a covariance which is independent of $\pmb{x}$.</p>
<p><img src="/images/PatternRecognition/c2/marginal-gaussians.png" alt="marginal-conditional Gaussian distribution"></p>
<h3 id="Maximum-likelihood-for-the-Gaussian"><a href="#Maximum-likelihood-for-the-Gaussian" class="headerlink" title="Maximum likelihood for the Gaussian"></a>Maximum likelihood for the Gaussian</h3><p>Given a data set $\pmb{X} = (\pmb{x_1}, \cdots , \pmb{x_N})^T$ in which the observations $\lbrace \pmb{x_n} \rbrace$ are assumed to be drawn independently from a multivariate Gaussian distribution, we can estimate the parameters of the distribution by maximum likelihood, and get<br>$$<br>\pmb{\mu_{ML}} = \frac{1}{N} \sum_{n=1}^{N}\pmb{x_n}<br>$$<br>$$<br>\pmb{\widetilde{\Sigma}} = \frac{1}{N-1} \sum_{n=1}^{N}(\pmb{x_n}-\pmb{\mu_{ML}})(\pmb{x_n}-\pmb{\mu_{ML}})^T<br>$$</p>
<h3 id="Sequential-estimation"><a href="#Sequential-estimation" class="headerlink" title="Sequential estimation"></a>Sequential estimation</h3><p>Sequential methods allow data points to be processed one at a time and then discarded and are important for on-line applications, and also where large data sets are involved so that batch processing of all data points at once is infeasible.</p>
<h3 id="Bayesian-inference-for-the-Gaussian"><a href="#Bayesian-inference-for-the-Gaussian" class="headerlink" title="Bayesian inference for the Gaussian"></a>Bayesian inference for the Gaussian</h3><p>The maximum likelihood framework gave point estimates for the parameters $\pmb{\mu}$ and $\pmb{\Sigma}$. Now we develop a Bayesian treatment by introducing prior distributions over these parameters.</p>
<p>We shall suppose that the variance $\sigma^2$ is known, and we consider the task of inferring the mean $\mu$ given a set of $N$ observations $\pmb{X} = \lbrace x_1, \cdots , x_N \rbrace $. The likelihood function, that is the probability of the observed data given $\mu$, viewed as a function of $\mu$, is given by<br>$$<br>\begin{aligned}<br>p(\pmb{X}|\mu) &amp;= \prod_{n=1}^{N} p(x_n|\mu) \\<br>&amp;= \frac{1}{(2\pi\sigma^2)^{N/2}} exp \lbrace -\frac{1}{2\sigma^2} \sum_{n=1}^{N} (x_n - \mu)^2\rbrace<br>\end{aligned}<br>\tag{2.137}<br>$$</p>
<p>the posterior distribution is given by,<br>$$<br>p(\mu|\pmb{X}) \propto p(\pmb{X}|\mu)p(\mu)<br>\tag{2.139}<br>$$</p>
<p>where<br>$$<br>p(\mu) = N(\mu|mu_0, \sigma_0^2)<br>\tag{2.138}<br>$$</p>
<p>thus, we get<br>$$<br>\mu_N = \frac{\sigma^2}{N\sigma_0^2 + \sigma^2}\mu_0 + \frac{N\sigma_0^2}{N\sigma_0^2+\sigma^2}\mu_{ML}<br>\tag{2.141}<br>$$<br>$$<br>\frac{1}{\sigma_N^2} = \frac{1}{\sigma_0^2} + \frac{N}{\sigma^2}<br>\tag{2.142}<br>$$</p>
<p>In fact, the Bayesian paradigm leads very naturally to a sequential view of the inference problem. To see this in the context of the inference of the mean of a Gaussian, we write the posterior distribution with the contribution from the final data point $\pmb{x_N}$ separated out so that</p>
<p>$$<br>p(\pmb{\mu}|D) \propto [ p(\pmb{\mu}) \prod_{n=1}^{N-1} p(\pmb{x_n}|\pmb{\mu}) ] p(\pmb{x_N}|\pmb{\mu})<br>$$</p>
<p>The term in square brackets is (up to a normalization coefficient) just the posterior distribution after observing $N − 1$ data points. We see that this can be viewed as a prior distribution, which is combined using Bayes’ theorem with the likelihood function associated with data point $\pmb{x_N}$ to arrive at the posterior distribution after observing $N$ data points. This sequential view of Bayesian inference is very general and applies to any problem in which the observed data are assumed to be independent and identically distributed.</p>
<p>So far, we have assumed that the variance of the Gaussian distribution over the data is known and our goal is to infer the mean. Now let us suppose that the mean is known and we wish to infer the variance.</p>
<p>Let $\lambda \equiv \frac{1}{\sigma^2}$, then, </p>
<p>$$<br>\begin{aligned}<br>p(\pmb{X}|\lambda) &amp;= \prod_{n=1}^{N} N(x_n | \mu, \lambda^{-1}) \\<br>&amp;\propto \lambda^{N/2} exp \lbrace -\frac{\lambda}{2} \sum_{n=1}^{N} (x_n - \mu)^2\rbrace<br>\end{aligned}<br>\tag{2.145}<br>$$</p>
<p>the posterior distribution we get is<br>$$<br>p(\lambda|\pmb{X}) \propto \lambda^{a_0 - 1} \lambda^{N/2} exp \lbrace -b_0\lambda - \frac{\lambda}{2} \sum_{n=1}^{N} (x_n - \mu)^2 \rbrace<br>\tag{2.149}<br>$$<br>where the prior distribution of $\lambda$ is<br>$$<br>Gam(\lambda|a,b) = \frac{1}{\Gamma(a)} b^a \lambda^{a-1} exp(-b\lambda)<br>\tag{2.146}<br>$$</p>
<p>we get<br>$$<br>a_N = a_0 + \frac{N}{2}<br>\tag{2.150}<br>$$</p>
<p>$$<br>b_N = b_0 + \frac{1}{2} \sum_{n=1}^{N} (x_n - \mu)^2 = b_0 + \frac{N}{2} \sigma^2_{ML}<br>\tag{2.151}<br>$$</p>
<p><img src="/images/PatternRecognition/c2/gaussian-bayse.png" alt="bayesian gaussian distribution"></p>
<h3 id="Student’s-t-distribution"><a href="#Student’s-t-distribution" class="headerlink" title="Student’s t-distribution"></a>Student’s t-distribution</h3><p>If we have a univariate Gaussian $N(x|\mu, \tau)$ together with a Gamma prior $Gam(\tau | a, b)$ and we integrate out the precision, we obtain the marginal distribution of $x$ in the form</p>
<p>$$<br>\begin{aligned}<br>p(x | \mu, a, b) &amp;= \int_0^\infty N(x | \mu, \tau^{-1}) Gam(\tau | a, b) d\tau \\<br>&amp;= \frac{b^a}{\Gamma(a)} (\frac{1}{2\pi})^{1/2} [b+\frac{(x-\mu)^2}{2}]^{-a-1/2} \Gamma(a+1/2)<br>\end{aligned}<br>\tag{2.158}<br>$$</p>
<p>By convention we define new parameters given by $ν = 2a$ and $\lambda = a / b$, in terms of which the distribution $p(x|\mu, a, b)$ takes the form</p>
<p>$$<br>St(x|\mu, \lambda, v) = \frac{\Gamma (v / 2 + 1 / 2)}{\Gamma (v/2)} (\frac{\lambda}{\pi v})^{1/2} [1 +  \frac{\lambda (x - \mu)^2}{v}]^{-v/2-1/2}<br>\tag{2.159}<br>$$</p>
<p>which is known as Student’s t-distribution. The parameter $\lambda$ is sometimes called the <strong>precision</strong> of the t-distribution, even though it is not in general equal to the inverse of the variance. The parameter $v$ is called the <strong>degrees of freedom</strong>, and its effect is illustrated in Figure 2.15.</p>
<p>From (2.158), we see that Student’s t-distribution is obtained by adding up an infinite number of Gaussian distributions having the same mean but different precisions.This gives the tdistribution an important property called robustness, which means that it is much less sensitive than the Gaussian to the presence of a few data points which are outliers. The <strong>robustness</strong> of the t-distribution is illustrated in Figure 2.16, which compares the maximum likelihood solutions for a Gaussian and a t-distribution</p>
<p><img src="/images/PatternRecognition/c2/student-t.png" alt="bayesian gaussian distribution"></p>
<p>$$<br>St(\pmb{x}|\pmb{\mu, \Lambda}, v) = \frac{\Gamma(D/2+v/2)}{\Gamma(v/2)} \frac{|\Lambda|^{1/2}}{(\pi v)^{D/2}} [1+\frac{\Delta^2}{v}]^{-D/2-v/2}<br>\tag{2.162}<br>$$<br>where<br>$$<br>\Delta^2 = (\pmb{x-\mu}^T)\Lambda(\pmb{x-\mu})<br>\tag{2.163}<br>$$</p>
<p>This is the multivariate form of Student’s t-distribution and satisfies the following properties<br>$$<br>E[\pmb{x}] = \pmb{\mu}, v &gt; 1\\<br>cov[\pmb{x}] = \frac{v}{(v-2)}\Lambda^{-1}, v &gt; 2\\<br>mode[\pmb{x}] = \pmb{\mu}<br>$$</p>
<h3 id="Periodic-variables"><a href="#Periodic-variables" class="headerlink" title="Periodic variables"></a>Periodic variables</h3><h3 id="Mixtures-of-Gaussians"><a href="#Mixtures-of-Gaussians" class="headerlink" title="Mixtures of Gaussians"></a>Mixtures of Gaussians</h3><p>We therefore consider a superposition of K Gaussian densities of the form<br>$$<br>p(\pmb{x}) = \sum_{k=1}^{K} \pi_k N(\pmb{x}|\pmb{\mu_K, \Sigma_k})<br>\tag{2.188}<br>$$<br>where<br>$$<br>\sum_{k=1}^K \pi_k = 1<br>\tag{2.189}<br>$$<br>which is called a <strong>mixture of Gaussians</strong>.</p>
<p><img src="/images/PatternRecognition/c2/gaussian-mixture.png" alt="gaussian-mixture"></p>
<p>From the sum and product rules, the marginal density is given by<br>$$<br>p(\pmb{x}) = \sum_{k=1}^{K} p(k) p(\pmb{x}|k)<br>\tag{2.191}<br>$$</p>
<p>we can view $\pi_k = p(k)$ as the prior probability of picking the $k^{th}$ component, and the density $N(\pmb{x}|\pmb{\mu_k}, \Sigma_k) = p(\pmb{x}|k)$ as the probability of $\pmb{x}$ conditioned on $k$.</p>
<p>An important role is played by the posterior probabilities $p(k|\pmb{x})$, which are also known as responsibilities. From Bayes’ theorem it is given by</p>
<p>$$<br>\begin{aligned}<br>\gamma_k(\pmb{x}) &amp;\equiv p(k|\pmb{x}) \\<br>&amp;= \frac{p(k)p(\pmb{x}|k)}{\sum_l p(l)p(\pmb{x}|l)}\\<br>&amp;= \frac{\pi_k N(\pmb{x}|\pmb{\mu_k}, \Sigma_k)}{\sum_l \pi_l N(\pmb{x}|\pmb{\mu_l}, \Sigma_l)}<br>\end{aligned}<br>\tag{2.192}<br>$$</p>
<p>As a result, the maximum likelihood solution for the parameters no longer has a closed-form analytical solution. Alternatively we can employ a powerful framework called expectation maximization,</p>
<h2 id="The-Exponential-Family"><a href="#The-Exponential-Family" class="headerlink" title="The Exponential Family"></a>The Exponential Family</h2><p>The exponential family of distributions over $\pmb{x}$, given parameters $\eta$, is defined to be the set of distributions of the form</p>
<p>$$<br>p(\pmb{x}|\pmb{\eta}) = h(\pmb{x})g(\pmb{\eta}) exp \lbrace \pmb{\eta^T} u(\pmb{x}) \rbrace<br>\tag{2.194}<br>$$<br>Here $\pmb{\eta}$ are called the <em>natural parameters</em> of the distribution, and $u(\pmb{x})$ is some function of $\pmb{x}$. The function $g(\pmb{\eta})$ can be interpreted as the coefficient that ensures that the distribution is normalized and therefore satisfies<br>$$<br>g(\pmb{\eta}) \int h(\pmb{x}) exp \lbrace \pmb{\eta^T} u(\pmb{x}) \rbrace d\pmb{x} = 1<br>\tag{2.159}<br>$$</p>
<h3 id="Maximum-likelihood-and-sufficient-statistics"><a href="#Maximum-likelihood-and-sufficient-statistics" class="headerlink" title="Maximum likelihood and sufficient statistics"></a>Maximum likelihood and sufficient statistics</h3><p>Taking the gradient of both sides of (2.195) with respect to $\pmb{\eta}$, we have</p>
<p>$$<br>\nabla g(\pmb{\eta}) \int h(\pmb{x}) exp \lbrace \pmb{\eta}^T u(\pmb{x}) \rbrace d\pmb{x} + g(\pmb{\eta}) \int h(\pmb{x}) exp \lbrace \pmb{\eta}^T u(\pmb{x}) \rbrace u(\pmb{x}) d\pmb{x} = 0<br>\tag{2.224}<br>$$</p>
<p>thus, we get</p>
<p>$$<br>-\nabla \ln g(\pmb{\eta}) = E[u(\pmb{x})]<br>\tag{2.226}<br>$$</p>
<p>Now consider a set of independent identically distributed data denoted by $\pmb{X} = \lbrace \pmb{x_1}, \cdots, \pmb{x_n} \rbrace$, for which the <u>likelihood function</u> is given by</p>
<p>$$<br>p(\pmb{X}|\pmb{\eta}) = (\prod_{n=1}^{N} h(\pmb{x_n})) g(\pmb{\eta})^N exp \lbrace \pmb{\eta}^T \sum_{n=1}^{N} u(\pmb{x_n})\rbrace<br>$$</p>
<p>Setting the gradient of $\ln p(\pmb{X}|\pmb{\eta})$ with respect to $\pmb{\eta}$ to zero, we get the following condition to be satisfied by the maximum likelihood estimator $\pmb{\eta}_{ML}$</p>
<p>$$<br>-\nabla \ln g(\pmb{\eta_{ML}}) = \frac{1}{N} \sum_{n=1}^{N} u(\pmb{x_n})<br>\tag{2.228}<br>$$</p>
<p>We see that the solution for the maximum likelihood estimator depends on the data only through $\sum_n u(\pmb{x_n})$, which is therefore called the <strong><em>sufficient statistic of the distribution</em></strong> (2.194). We do not need to store the entire data set itself but only the value of the sufficient statistic. </p>
<p>For the Bernoulli distribution, for example, the function $u(\pmb{x})$ is given just by $\pmb{x}$ and so we need only keep the sum of the data points $\lbrace \pmb{x_n} \rbrace $, whereas for the Gaussian $u(\pmb{x}) = (\pmb{x}, \pmb{x^2})^T$, and so we should keep both the sum of $\lbrace \pmb{x_n} \rbrace $ and the sum of $\lbrace \pmb{x_n^2} \rbrace $.</p>
<p>If we consider the limit $N \rightarrow \infty$, then the right-hand side of (2.228) becomes $E[u(\pmb{x})]$, and so by comparing with (2.226) we see that in this limit $\pmb{\eta_{ML}}$ will equal the true value $\pmb{\eta}$.</p>
<h3 id="Conjugate-priors"><a href="#Conjugate-priors" class="headerlink" title="Conjugate priors"></a>Conjugate priors</h3><p>For any member of the exponential family (2.194), there exists a conjugate prior that can be written in the form</p>
<p>$$<br>p(\pmb{\eta}|\pmb{\chi}, v) = f(\pmb{\chi}, v) g(\pmb{\eta})^v exp \lbrace v \pmb{\eta}^T \pmb{\chi} \rbrace<br>\tag{2.229}<br>$$<br>the posterior distribution is like<br>$$<br>p(\pmb{\eta}|\pmb{X}, \pmb{\chi}, v) \propto g(\pmb{\eta})^{v+N} exp \lbrace \pmb{\eta}^T (\sum_{n=1}^N u(\pmb{x_n}) + v\pmb{\chi})\rbrace<br>$$</p>
<h3 id="Noninformative-priors"><a href="#Noninformative-priors" class="headerlink" title="Noninformative priors"></a>Noninformative priors</h3><h2 id="Nonparametric-Methods"><a href="#Nonparametric-Methods" class="headerlink" title="Nonparametric Methods"></a>Nonparametric Methods</h2><p>Throughout this chapter, we have focussed on the use of probability distributions having specific functional forms governed by a small number of parameters whose values are to be determined from a data set. This is called the <strong><em>parametric approach to density modelling</em></strong>.</p>
<p>An important limitation of this approach is that the chosen density might be a poor model of the distribution that generates the data, which can result in poor predictive performance. For instance, if the process that generates the data is <strong><em>multimodal</em></strong>, then this aspect of the distribution can never be captured by a Gaussian, which is necessarily unimodal.</p>
<p>we turn now to a discussion of two widely used nonparametric techniques for density estimation, kernel estimators and nearest neighbours.</p>
<h3 id="Kernel-density-estimators"><a href="#Kernel-density-estimators" class="headerlink" title="Kernel density estimators"></a>Kernel density estimators</h3><p>kernel density estimators:</p>
<p>$$<br>p(\pmb{x}) = \frac{1}{N} \sum_{n=1}^N \frac{1}{h^D} k(\frac{\pmb{x} - \pmb{x_n}}{h})<br>\tag{2.249}<br>$$<br>We can obtain a smoother density model if we choose a smoother kernel function, and a common choice is the Gaussian, which gives rise to the following kernel density model<br>$$<br>p(\pmb{x}) = \frac{1}{N} \sum_{n=1}^N \frac{1}{(2\pi h^2)^{1/2}} exp \lbrace -\frac{||\pmb{x}-\pmb{x_n}||^2}{2h^2} \rbrace<br>\tag{2.250}<br>$$</p>
<p><img src="/images/PatternRecognition/c2/kernel.png" alt="kernel &amp; nearest-neighbour"></p>
<h3 id="Nearest-neighbour-methods"><a href="#Nearest-neighbour-methods" class="headerlink" title="Nearest-neighbour methods"></a>Nearest-neighbour methods</h3>
        </div>
        
        <div class="level is-size-7 is-uppercase">
            <div class="level-start">
                <div class="level-item">
                    <span class="is-size-6 has-text-grey has-mr-7">#</span>
                    <a class="has-link-grey -link" href="/tags/MachineLearning/" rel="tag">MachineLearning</a>
                </div>
            </div>
        </div>
        
        
        
        
<div class="sharethis-inline-share-buttons"></div>
<script type='text/javascript' src='//platform-api.sharethis.com/js/sharethis.js#property=5e58d41ecdbda60012fcd87d&amp;product=inline-share-buttons&amp;cms=sop' async='async'></script>

        
    </div>
</div>



<div class="card">
    <div class="card-content">
        <h3 class="menu-label has-text-centered">Like this article? Support the author with</h3>
        <div class="buttons is-centered">
            
                
<a class="button is-info donate">
    <span class="icon is-small">
        <i class="fab fa-alipay"></i>
    </span>
    <span>Alipay</span>
    <div class="qrcode"><img src="/images/Alipay.jpg" alt="Alipay"></div>
</a>

                
                
<a class="button is-success donate">
    <span class="icon is-small">
        <i class="fab fa-weixin"></i>
    </span>
    <span>Wechat</span>
    <div class="qrcode"><img src="/images/Wechatpay.jpg" alt="Wechat"></div>
</a>

                
        </div>
    </div>
</div>



<div class="card card-transparent">
    <div class="level post-navigation is-flex-wrap is-mobile">
        
        <div class="level-start">
            <a class="level level-item has-link-grey  article-nav-prev" href="/MachineLearning/PatternRecognition/PatterRecognition-C4-Linear-Models-For-Classification/">
                <i class="level-item fas fa-chevron-left"></i>
                <span class="level-item">PatterRecognition-C4-Linear-Models-For-Classification</span>
            </a>
        </div>
        
        
        <div class="level-end">
            <a class="level level-item has-link-grey  article-nav-next" href="/MachineLearning/PatternRecognition/PatterRecognition-C1-Introduction/">
                <span class="level-item">PatterRecognition-C1-Introduction</span>
                <i class="level-item fas fa-chevron-right"></i>
            </a>
        </div>
        
    </div>
</div>



<div class="card">
    <div class="card-content">
        <h3 class="title is-5 has-text-weight-normal">Comments</h3>
        
<div id="comment-container"></div>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.4.1/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1.4.1/dist/gitalk.min.js"></script>
<script>
    var gitalk = new Gitalk({
        clientID: 'f7d6d05297c7a1b94ee1',
        clientSecret: 'f3c964e1d94edd347ea044c1bc1ecdadac432326',
        id: '5787b2266952b81341fdafa43b8f7141',
        repo: 'keneyr.github.io',
        owner: 'Keneyr',
        admin: "Keneyr",
        createIssueManually: false,
        distractionFreeMode: false
    })
    gitalk.render('comment-container')
</script>

    </div>
</div>
</div>
                




<div class="column is-4-tablet is-2-desktop is-3-widescreen  has-order-1 column-left ">
    
        
<div class="card widget">
    <div class="card-content">
        <nav class="level">
            <div class="level-item has-text-centered" style="flex-shrink: 1">
                <div>
                    
                    <figure class="image is-128x128 has-mb-6">
                        <img class="is-rounded" src="/images/anna.jpg" alt="Anna">
                    </figure>
                    
                    <p class="is-size-4 is-block">
                        Anna
                    </p>
                    
                    
                    <p class="is-size-6 is-block">
                        Game Programmer
                    </p>
                    
                    
                    <p class="is-size-6 is-flex is-flex-center has-text-grey">
                        <i class="fas fa-map-marker-alt has-mr-7"></i>
                        <span>Shanghai,China</span>
                    </p>
                    
                </div>
            </div>
        </nav>
        <nav class="level is-mobile">
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Posts
                    </p>
                    <a href="/archives">
                        <p class="title has-text-weight-normal">
                            90
                        </p>
                    </a>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Categories
                    </p>
                    <a href="/categories">
                        <p class="title has-text-weight-normal">
                            22
                        </p>
                    </a>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Tags
                    </p>
                    <a href="/tags">
                        <p class="title has-text-weight-normal">
                            17
                        </p>
                    </a>
                </div>
            </div>
        </nav>
        
        <div class="level">
            <a class="level-item button is-link is-rounded" href="https://github.com/Keneyr" target="_blank" rel="noopener">
                Follow</a>
        </div>
        
        
        
    </div>
</div>
    
        

    <div class="card widget" id="toc">
        <div class="card-content">
            <div class="menu">
                <h3 class="menu-label">
                    Catalogue
                </h3>
                <ul class="menu-list"><li>
        <a class="is-flex" href="#Binary-Variables">
        <span class="has-mr-6">1</span>
        <span>Binary Variables</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#The-beta-distribution">
        <span class="has-mr-6">1.1</span>
        <span>The beta distribution</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#Multinomial-Variables">
        <span class="has-mr-6">2</span>
        <span>Multinomial Variables</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#The-Dirichlet-distribution">
        <span class="has-mr-6">2.1</span>
        <span>The Dirichlet distribution</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#The-Gaussian-Distribution">
        <span class="has-mr-6">3</span>
        <span>The Gaussian Distribution</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Conditional-Gaussian-distributions">
        <span class="has-mr-6">3.1</span>
        <span>Conditional Gaussian distributions</span>
        </a></li><li>
        <a class="is-flex" href="#Marginal-Gaussian-distributions">
        <span class="has-mr-6">3.2</span>
        <span>Marginal Gaussian distributions</span>
        </a></li><li>
        <a class="is-flex" href="#Bayes’-theorem-for-Gaussian-variables">
        <span class="has-mr-6">3.3</span>
        <span>Bayes’ theorem for Gaussian variables</span>
        </a></li><li>
        <a class="is-flex" href="#Maximum-likelihood-for-the-Gaussian">
        <span class="has-mr-6">3.4</span>
        <span>Maximum likelihood for the Gaussian</span>
        </a></li><li>
        <a class="is-flex" href="#Sequential-estimation">
        <span class="has-mr-6">3.5</span>
        <span>Sequential estimation</span>
        </a></li><li>
        <a class="is-flex" href="#Bayesian-inference-for-the-Gaussian">
        <span class="has-mr-6">3.6</span>
        <span>Bayesian inference for the Gaussian</span>
        </a></li><li>
        <a class="is-flex" href="#Student’s-t-distribution">
        <span class="has-mr-6">3.7</span>
        <span>Student’s t-distribution</span>
        </a></li><li>
        <a class="is-flex" href="#Periodic-variables">
        <span class="has-mr-6">3.8</span>
        <span>Periodic variables</span>
        </a></li><li>
        <a class="is-flex" href="#Mixtures-of-Gaussians">
        <span class="has-mr-6">3.9</span>
        <span>Mixtures of Gaussians</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#The-Exponential-Family">
        <span class="has-mr-6">4</span>
        <span>The Exponential Family</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Maximum-likelihood-and-sufficient-statistics">
        <span class="has-mr-6">4.1</span>
        <span>Maximum likelihood and sufficient statistics</span>
        </a></li><li>
        <a class="is-flex" href="#Conjugate-priors">
        <span class="has-mr-6">4.2</span>
        <span>Conjugate priors</span>
        </a></li><li>
        <a class="is-flex" href="#Noninformative-priors">
        <span class="has-mr-6">4.3</span>
        <span>Noninformative priors</span>
        </a></li></ul></li><li>
        <a class="is-flex" href="#Nonparametric-Methods">
        <span class="has-mr-6">5</span>
        <span>Nonparametric Methods</span>
        </a><ul class="menu-list"><li>
        <a class="is-flex" href="#Kernel-density-estimators">
        <span class="has-mr-6">5.1</span>
        <span>Kernel density estimators</span>
        </a></li><li>
        <a class="is-flex" href="#Nearest-neighbour-methods">
        <span class="has-mr-6">5.2</span>
        <span>Nearest-neighbour methods</span>
        </a></li></ul></li></ul>
            </div>
        </div>
    </div>

    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            Links
        </h3>
        <ul class="menu-list">
        
            <li>
                <a class="level is-mobile" href="https://www.youtube.com/@Gdconf/videos" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">GDC</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">www.youtube.com</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level is-mobile" href="https://www.esports.net/" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">Esports</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">www.esports.net</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level is-mobile" href="https://www.blender.org/" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">blender</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">www.blender.org</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level is-mobile" href="https://dl.acm.org/topic/ccs2012/10010147.10010371.10010352" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">acmLibrary</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">dl.acm.org</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level is-mobile" href="https://www.physicsbasedanimation.com/" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">physicalAnimation</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">www.physicsbasedanimation.com</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level is-mobile" href="https://graphics.pixar.com/research/" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">Pixar Studio</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">graphics.pixar.com</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level is-mobile" href="https://www.ubisoft.com/en-us/studio/laforge" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">Ubisoft Studio</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">www.ubisoft.com</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level is-mobile" href="https://theorangeduck.com/" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">Daniel Holden</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">theorangeduck.com</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level is-mobile" href="https://www.ode.org/" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">ODE</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">www.ode.org</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level is-mobile" href="https://github.com/NVIDIAGameWorks/PhysX/tree/4.1" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">PhysX</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">github.com</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level is-mobile" href="https://github.com/google-deepmind/mujoco" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">mujoco</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">github.com</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level is-mobile" href="https://rodolphe-vaillant.fr/" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">rodolphe</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">rodolphe-vaillant.fr</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level is-mobile" href="https://arrowinmyknee.com/" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">arrowinmyknee</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">arrowinmyknee.com</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level is-mobile" href="https://www.3dgep.com/" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">3dgep</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">www.3dgep.com</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level is-mobile" href="http://www.library.fudan.edu.cn/wjzx/2019njybgjskt/list1.htm" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">excellentMathBooks</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">www.library.fudan.edu.cn</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level is-mobile" href="https://www.deeplearningbook.org/" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">DeepLearningBook</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">www.deeplearningbook.org</span>
                    </span>
                </a>
            </li>
        
            <li>
                <a class="level is-mobile" href="http://dpkingma.com/" target="_blank" rel="noopener">
                    <span class="level-left">
                        <span class="level-item">Probability Model</span>
                    </span>
                    <span class="level-right">
                        <span class="level-item tag">dpkingma.com</span>
                    </span>
                </a>
            </li>
        
        </ul>
        </div>
    </div>
</div>

    
        
<div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Categories
            </h3>
            <ul class="menu-list">
            <li>
        <a class="level is-marginless" href="/categories/CS/">
            <span class="level-start">
                <span class="level-item">CS</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">4</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/CS/Advanced-CPP/">
            <span class="level-start">
                <span class="level-item">Advanced CPP</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">3</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/CS/Algorithms/">
            <span class="level-start">
                <span class="level-item">Algorithms</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/GameProgramming/">
            <span class="level-start">
                <span class="level-item">GameProgramming</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">4</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/GameProgramming/System/">
            <span class="level-start">
                <span class="level-item">System</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">4</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/Graphics/">
            <span class="level-start">
                <span class="level-item">Graphics</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">19</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/Graphics/Animation/">
            <span class="level-start">
                <span class="level-item">Animation</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">13</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Graphics/Geometry/">
            <span class="level-start">
                <span class="level-item">Geometry</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">3</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Graphics/Rendering/">
            <span class="level-start">
                <span class="level-item">Rendering</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">3</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/MachineLearning/">
            <span class="level-start">
                <span class="level-item">MachineLearning</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">14</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/MachineLearning/PatternRecognition/">
            <span class="level-start">
                <span class="level-item">PatternRecognition</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">14</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/Math/">
            <span class="level-start">
                <span class="level-item">Math</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">41</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/Math/Calculus/">
            <span class="level-start">
                <span class="level-item">Calculus</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">17</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Math/Linear-Algebra/">
            <span class="level-start">
                <span class="level-item">Linear Algebra</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">9</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Math/Numerical-Analysis/">
            <span class="level-start">
                <span class="level-item">Numerical Analysis</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">14</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Math/Variation/">
            <span class="level-start">
                <span class="level-item">Variation</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li></ul></li><li>
        <a class="level is-marginless" href="/categories/Paper/">
            <span class="level-start">
                <span class="level-item">Paper</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">8</span>
            </span>
        </a><ul><li>
        <a class="level is-marginless" href="/categories/Paper/Human-Pose/">
            <span class="level-start">
                <span class="level-item">Human Pose</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">2</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Paper/Motion-Generation/">
            <span class="level-start">
                <span class="level-item">Motion Generation</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Paper/Sketch-Animation/">
            <span class="level-start">
                <span class="level-item">Sketch Animation</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">2</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Paper/Sketch-Consolidation/">
            <span class="level-start">
                <span class="level-item">Sketch Consolidation</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">2</span>
            </span>
        </a></li><li>
        <a class="level is-marginless" href="/categories/Paper/Sketch-Generation/">
            <span class="level-start">
                <span class="level-item">Sketch Generation</span>
            </span>
            <span class="level-end">
                <span class="level-item tag">1</span>
            </span>
        </a></li></ul></li>
            </ul>
        </div>
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Tag Cloud
        </h3>
        <a href="/tags/Algorithms/" style="font-size: 10px;">Algorithms</a> <a href="/tags/Animation/" style="font-size: 17.14px;">Animation</a> <a href="/tags/CPP/" style="font-size: 12.86px;">CPP</a> <a href="/tags/Calculus/" style="font-size: 20px;">Calculus</a> <a href="/tags/CurveFitting-of-Sketches/" style="font-size: 10px;">CurveFitting of Sketches</a> <a href="/tags/GameProgramming/" style="font-size: 14.29px;">GameProgramming</a> <a href="/tags/Geometry/" style="font-size: 12.86px;">Geometry</a> <a href="/tags/Human-Pose/" style="font-size: 11.43px;">Human Pose</a> <a href="/tags/Linear-Algebra/" style="font-size: 15.71px;">Linear Algebra</a> <a href="/tags/MachineLearning/" style="font-size: 18.57px;">MachineLearning</a> <a href="/tags/Motion-Generation/" style="font-size: 10px;">Motion Generation</a> <a href="/tags/Numerical-Analysis/" style="font-size: 18.57px;">Numerical Analysis</a> <a href="/tags/Rendering/" style="font-size: 12.86px;">Rendering</a> <a href="/tags/Sketch-Animation/" style="font-size: 11.43px;">Sketch Animation</a> <a href="/tags/Sketh-Consolidatoin/" style="font-size: 10px;">Sketh Consolidatoin</a> <a href="/tags/Sketh-Facical-Generation/" style="font-size: 10px;">Sketh Facical Generation</a> <a href="/tags/Variation/" style="font-size: 10px;">Variation</a>
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Recent
        </h3>
        
        <article class="media">
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2024-01-22T04:29:46.000Z">2024-01-22</time></div>
                    <a href="/Paper/Human-Pose/Paper-MAPConNet-SelfSupervised-3D-Pose-Transfer-with-Mesh-and-Point-ConstrastiveLearning/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Paper-MAPConNet-SelfSupervised-3D-Pose-Transfer-with-Mesh-and-Point-ConstrastiveLearning</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Paper/">Paper</a> / <a class="has-link-grey -link" href="/categories/Paper/Human-Pose/">Human Pose</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2023-12-28T04:27:50.000Z">2023-12-28</time></div>
                    <a href="/CS/Algorithms/Algorithms-C1-Foundations/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Algorithms-C1-Foundations</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/CS/">CS</a> / <a class="has-link-grey -link" href="/categories/CS/Algorithms/">Algorithms</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2023-11-15T07:01:37.000Z">2023-11-15</time></div>
                    <a href="/Graphics/Animation/Animation-C14-Skinning/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Animation-C14-Skinning</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Graphics/">Graphics</a> / <a class="has-link-grey -link" href="/categories/Graphics/Animation/">Animation</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2023-11-14T07:38:58.000Z">2023-11-14</time></div>
                    <a href="/Graphics/Animation/Animation-C13-Learning-based-Animation/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Animation-C13-Learning-based-Animation</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Graphics/">Graphics</a> / <a class="has-link-grey -link" href="/categories/Graphics/Animation/">Animation</a>
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2023-11-10T08:40:44.000Z">2023-11-10</time></div>
                    <a href="/Math/Linear-Algebra/Algebra-Summary/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Algebra-Summary</a>
                    <p class="is-size-7 is-uppercase">
                        <a class="has-link-grey -link" href="/categories/Math/">Math</a> / <a class="has-link-grey -link" href="/categories/Math/Linear-Algebra/">Linear Algebra</a>
                    </p>
                </div>
            </div>
        </article>
        
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            Archives
        </h3>
        <ul class="menu-list">
        
        <li>
            <a class="level is-marginless" href="/archives/2024/01/">
                <span class="level-start">
                    <span class="level-item">January 2024</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2023/12/">
                <span class="level-start">
                    <span class="level-item">December 2023</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2023/11/">
                <span class="level-start">
                    <span class="level-item">November 2023</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">18</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2023/10/">
                <span class="level-start">
                    <span class="level-item">October 2023</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">51</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2023/09/">
                <span class="level-start">
                    <span class="level-item">September 2023</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">12</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2023/04/">
                <span class="level-start">
                    <span class="level-item">April 2023</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/04/">
                <span class="level-start">
                    <span class="level-item">April 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2020/03/">
                <span class="level-start">
                    <span class="level-item">March 2020</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">5</span>
                </span>
            </a>
        </li>
        
        </ul>
        </div>
    </div>
</div>
    
        <div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Tags
            </h3>
            <div class="field is-grouped is-grouped-multiline">
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Algorithms/">
                        <span class="tag">Algorithms</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Animation/">
                        <span class="tag">Animation</span>
                        <span class="tag is-grey">13</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/CPP/">
                        <span class="tag">CPP</span>
                        <span class="tag is-grey">3</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Calculus/">
                        <span class="tag">Calculus</span>
                        <span class="tag is-grey">17</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/CurveFitting-of-Sketches/">
                        <span class="tag">CurveFitting of Sketches</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/GameProgramming/">
                        <span class="tag">GameProgramming</span>
                        <span class="tag is-grey">4</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Geometry/">
                        <span class="tag">Geometry</span>
                        <span class="tag is-grey">3</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Human-Pose/">
                        <span class="tag">Human Pose</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Linear-Algebra/">
                        <span class="tag">Linear Algebra</span>
                        <span class="tag is-grey">9</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/MachineLearning/">
                        <span class="tag">MachineLearning</span>
                        <span class="tag is-grey">14</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Motion-Generation/">
                        <span class="tag">Motion Generation</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Numerical-Analysis/">
                        <span class="tag">Numerical Analysis</span>
                        <span class="tag is-grey">14</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Rendering/">
                        <span class="tag">Rendering</span>
                        <span class="tag is-grey">3</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Sketch-Animation/">
                        <span class="tag">Sketch Animation</span>
                        <span class="tag is-grey">2</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Sketh-Consolidatoin/">
                        <span class="tag">Sketh Consolidatoin</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Sketh-Facical-Generation/">
                        <span class="tag">Sketh Facical Generation</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
                <div class="control">
                    <a class="tags has-addons" href="/tags/Variation/">
                        <span class="tag">Variation</span>
                        <span class="tag is-grey">1</span>
                    </a>
                </div>
                
            </div>
        </div>
    </div>
</div>
    
    
        <div class="column-right-shadow is-hidden-widescreen ">
        
        </div>
    
</div>

                
            </div>
        </div>
    </section>
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    <img src="/images/beauty.jpg" alt="PatterRecognition-C2-Probability-Distributions" height="28">
                
                </a>
                <p class="is-size-7">
                &copy; 2024 Keneyr&nbsp;
                Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> & <a
                        href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a>
                
                <br>
                <span id="busuanzi_container_site_uv">
                Visited by <span id="busuanzi_value_site_uv">0</span> users
                </span>

                <span id="busuanzi_container_site_pv" class="theme-info">
                    | PageView: <span id="busuanzi_value_site_pv">span>
                    </span>

                
            <br><span id="timeDate">载入天数...</span><span id="times">载入时分秒...</span>
                </p>
            </div>
            <div class="level-end">
            
                <div class="field has-addons is-flex-center-mobile has-mt-5-mobile is-flex-wrap is-flex-middle">
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/">
                        
                        <i class="fab fa-creative-commons"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/">
                        
                        <i class="fab fa-creative-commons-by"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                </p>
                
                </div>
            
            </div>
        </div>
    </div>
</footer>
<script>
    var now = new Date(); 
    function createtime() { 
        var grt= new Date("2/28/2020 12:49:00");//此处修改你的建站时间或者网站上线时间 
        now.setTime(now.getTime()+250); 
        days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); 
        hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); 
        if(String(hnum).length ==1 ){hnum = "0" + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); 
        mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = "0" + mnum;} 
        seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); 
        snum = Math.round(seconds); if(String(snum).length ==1 ){snum = "0" + snum;} 
        document.getElementById("timeDate").innerHTML = "The site has been running "+dnum+" days "; 
        document.getElementById("times").innerHTML = hnum + " hours " + mnum + " minutes " + snum + " seconds"; 
    } 
setInterval("createtime()",250);
</script>

    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("en");</script>


<script>
var IcarusThemeSettings = {
    site: {
        url: 'https://keneyr.com',
        external_link: {"enable":true,"exclude":[]}
    },
    article: {
        highlight: {
            clipboard: true,
            fold: 'unfolded'
        }
    }
};
</script>


<script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>





<script src="/js/animation.js"></script>



<script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script>
<script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script>
<script src="/js/gallery.js" defer></script>



<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>


<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
});
</script>


<a id="back-to-top" title="Back to Top" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>














<script src="/js/main.js" defer></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something..." />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js" defer></script>
<link rel="stylesheet" href="/css/search.css">
<link rel="stylesheet" href="/css/insight.css">
    
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
<script type="text/javascript">
    var windowWidth = $(window).width();
    if (windowWidth > 480) {
      document.write('<script type="text/javascript" src="/js/src/snow.js"><\/script>');
    }
</script>  
</html>